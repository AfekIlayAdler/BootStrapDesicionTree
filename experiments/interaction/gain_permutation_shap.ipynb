{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "from os import chdir\n",
    "chdir(\"C:\\\\Users\\\\afeki\\\\OneDrive\\\\Desktop\\\\code\\\\BootStrapDesicionTree\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_boosting_trees.gradient_boosting_regressor import CartGradientBoostingRegressor, \\\n",
    "    CartGradientBoostingRegressorKfold\n",
    "from gradient_boosting_trees.gradient_boosting_abstract import GradientBoostingMachine\n",
    "from Tree.node import Leaf\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor,GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create simulated data\n",
    "$$ y = a_1 \\cdot x_1 + a_2 \\cdot I(x_2 \\in LEFT\\_GROUP) + \\sigma $$\n",
    "\n",
    "$$ x1 - N(0,1) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(model_name,model,X,y, transform_x = True, categorical_features = None):\n",
    "    if transform_x:\n",
    "        temp_x = X.copy()\n",
    "        if model_name == 'xgboost':\n",
    "            temp_x = xgb.DMatrix(temp_x)\n",
    "        elif model_name == 'catboost':\n",
    "            if categorical_features:\n",
    "                temp_x = Pool(temp_x , cat_features = categorical_features)\n",
    "            else:\n",
    "                temp_x = Pool(temp_x)\n",
    "        return np.mean(np.square(y - model.predict(temp_x)))\n",
    "    return np.mean(np.square(y - model.predict(X)))\n",
    "    \n",
    "    \n",
    "cat_features=[0]\n",
    "\n",
    "def permutation_feature_importance(model_name,model,X,y, categorical_features = None):\n",
    "    results = {}\n",
    "    mse = compute_mse(model_name, model,X,y, categorical_features = categorical_features)\n",
    "    for col in X.columns:\n",
    "        temp_x = X.copy()\n",
    "        temp_x[col] = np.random.permutation(temp_x[col])\n",
    "        if model_name == 'xgboost':\n",
    "            temp_x = xgb.DMatrix(temp_x)\n",
    "        elif model_name == 'catboost':\n",
    "            if categorical_features:\n",
    "                temp_x = Pool(temp_x , cat_features = categorical_features)\n",
    "            else:\n",
    "                temp_x = Pool(temp_x)\n",
    "        new_mse = compute_mse(model_name, model,temp_x,y, transform_x = False, categorical_features = categorical_features)\n",
    "        results[col] = new_mse - mse\n",
    "    results = pd.Series(results)\n",
    "    return results/results.sum()\n",
    "\n",
    "def get_x1_shap_value(model, x, columns = None):\n",
    "    if columns is None:\n",
    "        columns = x.columns\n",
    "    abs_shap_values = pd.DataFrame(shap.TreeExplainer(model, feature_perturbation = \"tree_path_dependent\").shap_values(x), columns = columns).apply(np.abs)\n",
    "    return (abs_shap_values.mean()/abs_shap_values.mean().sum())['x1']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d</td>\n",
       "      <td>3</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3\n",
       "0  d  3  d  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([['d','3', 'd',1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUR IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import all_experiments, create_x_y, n_experiments, get_fitted_model, create_one_hot_x_x_val, create_mean_imputing_x_x_val\n",
    "from config import RESULTS_DIR,N_EXPERIMENTS,N_ROWS, SIGMA, CATEGORY_COLUMN_NAME, Y_COL_NAME, MAX_DEPTH, LEARNING_RATE,VAL_RATIO, N_ESTIMATORS,MODELS_DIR, N_EXPERIMENTS, CATEGORIES, A_VALUES\n",
    "EXP_NAME = F\"interaction_{MAX_DEPTH}_nestimators_{N_ESTIMATORS}_learning_rate_{LEARNING_RATE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–‰         | 470/4830 [15:04:31<213:00:31, 175.88s/it]    "
     ]
    }
   ],
   "source": [
    "model_type= 'ours'\n",
    "for exp_number, category_size, a in tqdm(all_experiments(), total=n_experiments):\n",
    "    np.random.seed(exp_number)\n",
    "    for predictor_name, predictor in {'Kfold': CartGradientBoostingRegressorKfold,\n",
    "                                      'CartVanilla': CartGradientBoostingRegressor}.items():\n",
    "        try:\n",
    "            exp_name = F\"{EXP_NAME}__{predictor_name}_exp_{exp_number}_category_size_{category_size}_a_{a}\"\n",
    "            model_path = MODELS_DIR / F\"{exp_name}.pkl\"\n",
    "            exp_results_path = RESULTS_DIR / F\"{exp_name}.pkl\"\n",
    "            X, y = create_x_y(category_size, float(a))\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_RATIO, random_state=42)\n",
    "            X_train[Y_COL_NAME] = y_train\n",
    "            model = get_fitted_model(model_path, predictor, X_train, Y_COL_NAME)\n",
    "            fi_gain = pd.Series(model.compute_feature_importance(method='gain')).sort_index()\n",
    "            fi_gain /= fi_gain.sum()\n",
    "            fi_permutation_train = permutation_feature_importance(model_type,model,X_train,y_train)\n",
    "            fi_permutation_test = permutation_feature_importance(model_type,model, X_test, y_test)\n",
    "            temp_results = np.array([fi_gain['x1'], fi_permutation_train['x1'], fi_permutation_test['x1']])\n",
    "            results.setdefault((F\"{model_type}_{predictor_name}\", category_size, a),np.zeros(len(temp_results)))\n",
    "            results[(F\"{model_type}_{predictor_name}\", category_size, a)] += temp_results\n",
    "        except:\n",
    "            print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None \n",
    "model_type= 'sklearn'\n",
    "for exp_number, category_size, a in tqdm(all_experiments(), total=n_experiments):\n",
    "    np.random.seed(exp_number)\n",
    "    for predictor_name, _ in {'one_hot': GradientBoostingRegressor,\n",
    "                                      'mean_imputing': GradientBoostingRegressor}.items():\n",
    "        X, y = create_x_y(category_size, float(a))\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_RATIO, random_state=42)\n",
    "        if predictor_name == 'one_hot':\n",
    "            X_train, X_test = create_one_hot_x_x_val(X_train, X_test)\n",
    "        elif predictor_name == 'mean_imputing':\n",
    "            X_train, X_test = create_mean_imputing_x_x_val(X_train, y_train, X_test)\n",
    "    \n",
    "        model = GradientBoostingRegressor(max_depth=MAX_DEPTH, n_estimators=N_ESTIMATORS, learning_rate=LEARNING_RATE)\n",
    "        model.fit(X_train, y_train)\n",
    "        fi_gain = pd.Series(model.feature_importances_, index = X_train.columns)\n",
    "        fi_gain /= fi_gain.sum()\n",
    "        fi_permutation_train = permutation_feature_importance(model_type,model,X_train,y_train)\n",
    "        fi_permutation_test = permutation_feature_importance(model_type,model, X_test, y_test)\n",
    "        temp_results = np.array([fi_gain['x1'], fi_permutation_train['x1'], fi_permutation_test['x1'], get_x1_shap_value(model, X_train),get_x1_shap_value(model, X_test)])\n",
    "        results.setdefault((F\"{model_type}_{predictor_name}\", category_size, a),np.zeros(len(temp_results)))\n",
    "        results[(F\"{model_type}_{predictor_name}\", category_size, a)] += temp_results\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type= 'xgboost'\n",
    "for exp_number, category_size, a in tqdm(all_experiments(), total=n_experiments):\n",
    "    np.random.seed(exp_number)\n",
    "    for predictor_name, _ in {'one_hot': GradientBoostingRegressor,\n",
    "                                      'mean_imputing': GradientBoostingRegressor}.items():\n",
    "        X, y = create_x_y(category_size, float(a))\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_RATIO, random_state=42)\n",
    "        if predictor_name == 'one_hot':\n",
    "            X_train, X_test = create_one_hot_x_x_val(X_train, X_test)\n",
    "        elif predictor_name == 'mean_imputing':\n",
    "            X_train, X_test = create_mean_imputing_x_x_val(X_train,y_train, X_test)\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        param = {'max_depth': MAX_DEPTH - 1, 'eta': LEARNING_RATE, 'objective': 'reg:squarederror'}\n",
    "        bst = xgb.train(param, dtrain, N_ESTIMATORS)\n",
    "        fi_gain = pd.Series(bst.get_score(importance_type='gain'))\n",
    "        fi_gain /= fi_gain.sum()\n",
    "\n",
    "        fi_permutation_train = permutation_feature_importance(model_type,bst,X_train,y_train)\n",
    "        fi_permutation_test = permutation_feature_importance(model_type,bst, X_test, y_test)\n",
    "        temp_results = np.array([fi_gain['x1'],fi_permutation_train['x1'], fi_permutation_test['x1'],  get_x1_shap_value(bst, X_train),get_x1_shap_value(bst, X_test)])\n",
    "        results.setdefault((F\"{model_type}_{predictor_name}\", category_size, a),np.zeros(len(temp_results)))\n",
    "        results[(F\"{model_type}_{predictor_name}\", category_size, a)] += temp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type= 'catboost'\n",
    "for exp_number, category_size, a in tqdm(all_experiments(), total=n_experiments):\n",
    "    np.random.seed(exp_number)\n",
    "    for predictor_name in [\"vanilla\",\"mean_imputing\"]:\n",
    "        X, y = create_x_y(category_size, float(a))\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_RATIO, random_state=42)\n",
    "        if predictor_name == 'mean_imputing':\n",
    "            X_train, X_test = create_mean_imputing_x_x_val(X_train,y_train, X_test)\n",
    "            train_pool = Pool(X_train, y_train)\n",
    "            val_pool = Pool(X_test,y_test)\n",
    "        else:\n",
    "            train_pool = Pool(X_train, y_train, cat_features=[0])\n",
    "            val_pool = Pool(X_test,y_test, cat_features=[0])\n",
    "    \n",
    "        model = CatBoostRegressor(iterations=N_ESTIMATORS, \n",
    "                                  depth=MAX_DEPTH, \n",
    "                                  learning_rate=LEARNING_RATE, \n",
    "                                  loss_function='RMSE',logging_level = 'Silent')\n",
    "        model.fit(train_pool)\n",
    "        \n",
    "        fi_gain = pd.Series(model.feature_importances_, index = model.feature_names_)\n",
    "        fi_gain /= fi_gain.sum()\n",
    "        cat_feature = [0] if predictor_name == 'vanilla' else None\n",
    "        fi_permutation_train = permutation_feature_importance(model_type,model,X_train,y_train,  categorical_features = cat_feature)\n",
    "        fi_permutation_test = permutation_feature_importance(model_type,model, X_test, y_test, categorical_features = cat_feature)\n",
    "        temp_results = np.array([fi_gain['x1'], fi_permutation_train['x1'], fi_permutation_test['x1'],  get_x1_shap_value(model, train_pool, columns = X_train.columns),get_x1_shap_value(model, val_pool, columns = X_test.columns)])\n",
    "        results.setdefault((F\"{model_type}_{predictor_name}\", category_size, a),np.zeros(len(temp_results)))\n",
    "        results[(F\"{model_type}_{predictor_name}\", category_size, a)] += temp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for key in results.keys():\n",
    "    results[key] = results[key]/N_EXPERIMENTS\n",
    "    \n",
    "chdir(\"C:\\\\Users\\\\afeki\\\\OneDrive\\\\Desktop\\\\code\\\\BootStrapDesicionTree\\\\experiments\\\\interaction\\\\\")\n",
    "with open('results/experiments_results/detect_uninformative_feature_results.pkl', 'wb') as output:\n",
    "    pickle.dump(results, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments = list(set(exp[0] for exp in results.keys()))\n",
    "# categories = sorted(list(set(exp[1] for exp in results.keys())))\n",
    "# a_s = sorted(list(set(exp[2] for exp in results.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi_to_location = {'gain' :0, 'permutation_train': 1, 'permutation_test':2}\n",
    "# fi = 'gain'\n",
    "# a = 100\n",
    "# df = pd.DataFrame()\n",
    "# for exp in experiments:\n",
    "#     for cat in categories:   \n",
    "#         df.loc[exp,cat] = results[(exp,cat, a)][fi_to_location[fi]]\n",
    "        \n",
    "# plt.rcParams['figure.figsize'] = [20, 10]\n",
    "# ax = df.T.plot()\n",
    "# ax.set_xlabel(\"Number of categories\")\n",
    "# ax.set_ylabel(\"Feature importance of a random vector\")\n",
    "# ax.set_title(\"Feature importance of a random vector with K categories as a function of K\")\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fi_to_location = {'gain' :0, 'permutation_train': 1, 'permutation_test':2}\n",
    "# fi = 'gain'\n",
    "# a = 100 # [2, 10, 50, 100, 200]\n",
    "\n",
    "# def plot_feature_importance(method, a1):\n",
    "#     df = pd.DataFrame()\n",
    "#     for exp in experiments:\n",
    "#         for cat in categories:   \n",
    "#             df.loc[exp,cat] = results[(exp,cat, a1)][fi_to_location[method]]\n",
    "\n",
    "#     plt.rcParams['figure.figsize'] = [20, 10]\n",
    "#     ax = df.T.plot()\n",
    "#     ax.set_xlabel(\"Number of categories\")\n",
    "#     ax.set_ylabel(\"Feature importance of the category vaector\")\n",
    "#     ax.set_title(\"Feature importance of the category vaector with K categories as a function of K\")\n",
    "#     plt.legend(loc='upper right')\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
